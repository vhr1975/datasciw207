{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKsRDH5ZUdfasdv"
   },
   "source": [
    "# Lab 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "43534tdfgs-v"
   },
   "source": [
    "This lab connects all the pieces involved in training feed-forward fully connected neural networks. You will run a full set of experiments to explore different hyperparameters and hidden layer sizes for both the MNIST and FASHION_MNIST datasets, and report your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7X58hOMTUH-w"
   },
   "outputs": [],
   "source": [
    "# Import the libraries we'll use below.\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns  # for nicer plots\n",
    "sns.set(style=\"darkgrid\")  # default style\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import metrics\n",
    "tf.get_logger().setLevel('INFO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zL5O-SOu7kYN"
   },
   "source": [
    "## Datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYpm_zG37xay"
   },
   "source": [
    "### Fashion MNIST\n",
    "\n",
    "We load the fashion_mnist dataset as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "executionInfo": {
     "elapsed": 1733,
     "status": "ok",
     "timestamp": 1622667905055,
     "user": {
      "displayName": "Daniel Gillick",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9DrSMlwYnG9EolecuJqe8n9m7fpcje4_UbYrhQ10=s64",
      "userId": "01872965353911650729"
     },
     "user_tz": 420
    },
    "id": "load_auto_data_set_code",
    "outputId": "99d54f72-4abc-49f5-cdff-7d3833e3be50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: t-shirt\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "# Load the Fashion MNIST dataset.\n",
    "(X_train_fashion, Y_train_fashion), (X_test_fashion, Y_test_fashion) = fashion_mnist.load_data()\n",
    "X_train_fashion = X_train_fashion / 255.\n",
    "X_test_fashion = X_test_fashion / 255.\n",
    "\n",
    "# Flatten Y_train and Y_test, so they become vectors of label values.\n",
    "Y_train_fashion = Y_train_fashion.flatten()\n",
    "Y_test_fashion = Y_test_fashion.flatten()\n",
    "\n",
    "label_names = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',\n",
    "               'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
    "\n",
    "# Apply random shufflying to training examples.\n",
    "np.random.seed(0)\n",
    "indices = np.arange(X_train_fashion.shape[0])\n",
    "shuffled_indices = np.random.permutation(indices)\n",
    "X_train_fashion = X_train_fashion[shuffled_indices]\n",
    "Y_train_fashion = Y_train_fashion[shuffled_indices]\n",
    "\n",
    "# Show the first training example.\n",
    "print('Label: %s' %label_names[Y_train_fashion[0]])\n",
    "plt.imshow(X_train_fashion[0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ND9b1ShF745M"
   },
   "source": [
    "### MNIST\n",
    "\n",
    "We also load the (digits) mnist dataset in the same way. Note that the number of train/test examples as well as the data shapes are identical to fashion_mnist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "executionInfo": {
     "elapsed": 1305,
     "status": "ok",
     "timestamp": 1622667906354,
     "user": {
      "displayName": "Daniel Gillick",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9DrSMlwYnG9EolecuJqe8n9m7fpcje4_UbYrhQ10=s64",
      "userId": "01872965353911650729"
     },
     "user_tz": 420
    },
    "id": "ACD38quoz8D_",
    "outputId": "a294a8c6-de0a-421f-c17a-fe9ee1e79767"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "# Load the MNIST dataset.\n",
    "(X_train_digits, Y_train_digits), (X_test_digits, Y_test_digits) = mnist.load_data()\n",
    "X_train_digits = X_train_digits / 255\n",
    "X_test_digits = X_test_digits / 255\n",
    "\n",
    "# Flatten Y_train and Y_test, so they become vectors of label values.\n",
    "Y_train_digits = Y_train_digits.flatten()\n",
    "Y_test_digits = Y_test_digits.flatten()\n",
    "\n",
    "# Apply random shufflying to training examples.\n",
    "np.random.seed(0)\n",
    "indices = np.arange(X_train_digits.shape[0])\n",
    "shuffled_indices = np.random.permutation(indices)\n",
    "X_train_digits = X_train_digits[shuffled_indices]\n",
    "Y_train_digits = Y_train_digits[shuffled_indices]\n",
    "\n",
    "# Show the first training example.\n",
    "print('Label: %d' %Y_train_digits[0])\n",
    "plt.imshow(X_train_digits[0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09EpBz1w0_Nj"
   },
   "source": [
    "## Build a Model\n",
    "\n",
    "We will write a build_model function that allows for a range of experiments on both datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BWbRPrMyHZ2J"
   },
   "source": [
    "---\n",
    "### Exercise 1 (8points)\n",
    "\n",
    "Fill in code that implements the build_model function, including all the arguments listed in the function definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.sequential.Sequential object at 0x000002D058E70E50>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#How to add layers sequentially to keras model?\n",
    "\n",
    "#importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "\n",
    "#Loading Dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "#Model\n",
    "model = Sequential()\n",
    "\n",
    "#Adding Layers\n",
    "model.add(Dense(512))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-GeBGPGhQ5bu"
   },
   "outputs": [],
   "source": [
    "# n_classes = 10\n",
    "# hidden_layer_sizes =  []\n",
    "# activation =  tanh\n",
    "# optimizer =  Adam\n",
    "# learning_rate =  0.01\n",
    "\n",
    "def build_model(n_classes,\n",
    "                hidden_layer_sizes=[],\n",
    "                activation='relu',\n",
    "                optimizer='SGD',\n",
    "                learning_rate=0.01):\n",
    "  \"\"\"Build a multi-class logistic regression model using Keras.\n",
    "\n",
    "  Args:\n",
    "    n_classes: Number of output classes in the dataset.\n",
    "    hidden_layer_sizes: A list with the number of units in each hidden layer.\n",
    "    activation: The activation function to use for the hidden layers.\n",
    "    optimizer: The optimizer to use (SGD, Adam).\n",
    "    learning_rate: The desired learning rate for the optimizer.\n",
    "\n",
    "  Returns:\n",
    "    model: A tf.keras model (graph).\n",
    "  \"\"\"\n",
    "  tf.keras.backend.clear_session()\n",
    "  np.random.seed(0)\n",
    "  tf.random.set_seed(0)\n",
    "\n",
    "  # YOUR CODE HERE  \n",
    "  # model = NotImplemented\n",
    "  \n",
    "  # Use Keras Sequential API to build a logistic regression\n",
    "  model = tf.keras.Sequential()\n",
    "  # flatten \n",
    "  model.add(tf.keras.layers.Flatten(input_shape=(28,28)))  \n",
    "  \n",
    "  # TODO add a for loop\n",
    "  # add layers\n",
    "  model.add(tf.keras.layers.Dense(units=hidden_layer_sizes, activation=activation))\n",
    "  \n",
    "  # add output layer\n",
    "  model.add(tf.keras.layers.Dense(units=n_classes, activation='softmax'), name=\"Output\" )  \n",
    "  \n",
    "  # TODO add logic to handle different optimizers\n",
    "  # Use Categorical Crossentropy as our loss and the optimizer.\n",
    "  model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DO-d_F58Q-6O"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SYpd5gUeH9pn"
   },
   "source": [
    "## Run Experiments\n",
    "\n",
    "We can now run a suite of experiments to see how the hyperparameters and layer sizes effect performance. The train_and_evaluate function below can be used to run experiments and retrieve results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "executionInfo": {
     "elapsed": 22089,
     "status": "ok",
     "timestamp": 1622667987968,
     "user": {
      "displayName": "Daniel Gillick",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg9DrSMlwYnG9EolecuJqe8n9m7fpcje4_UbYrhQ10=s64",
      "userId": "01872965353911650729"
     },
     "user_tz": 420
    },
    "id": "OKeyZXLJJlA4",
    "outputId": "c3dd339a-443d-4830-ece9-adb2873ed629"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_classes = 10\n",
      "hidden_layer_sizes =  []\n",
      "activation =  tanh\n",
      "optimizer =  Adam\n",
      "learning_rate =  0.01\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a number, not 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_30840/1710266869.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     58\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test Accuracy: %1.4f'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[0mtrain_and_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_30840/1710266869.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(data, hidden_layer_sizes, activation, optimizer, learning_rate, num_epochs)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m   \u001b[1;31m# Build the model.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m   model = build_model(n_classes=10,\n\u001b[0m\u001b[0;32m     16\u001b[0m                       \u001b[0mhidden_layer_sizes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhidden_layer_sizes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                       \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_30840/2469503970.py\u001b[0m in \u001b[0;36mbuild_model\u001b[1;34m(n_classes, hidden_layer_sizes, activation, optimizer, learning_rate)\u001b[0m\n\u001b[0;32m     34\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m   \u001b[1;31m# add layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m   \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhidden_layer_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m   \u001b[1;31m# add layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\layers\\core\\dense.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m         activity_regularizer=activity_regularizer, **kwargs)\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0munits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munits\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m       raise ValueError(f'Received an invalid value for `units`, expected '\n",
      "\u001b[1;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'list'"
     ]
    }
   ],
   "source": [
    "def train_and_evaluate(data='digits',\n",
    "                       hidden_layer_sizes=[],\n",
    "                       activation='tanh',\n",
    "                       optimizer='Adam',\n",
    "                       learning_rate=0.01,\n",
    "                       num_epochs=5):\n",
    "\n",
    "  print(\"n_classes = 10\")\n",
    "  print(\"hidden_layer_sizes = \", hidden_layer_sizes)\n",
    "  print(\"activation = \", activation)\n",
    "  print(\"optimizer = \", optimizer)\n",
    "  print(\"learning_rate = \", learning_rate)\n",
    "  \n",
    "  # Build the model.\n",
    "  model = build_model(n_classes=10,\n",
    "                      hidden_layer_sizes=hidden_layer_sizes,\n",
    "                      activation=activation,\n",
    "                      optimizer=optimizer,\n",
    "                      learning_rate=learning_rate)\n",
    "\n",
    "  # Select the dataset.\n",
    "  if data == 'digits':\n",
    "    X_train = X_train_digits\n",
    "    X_test = X_test_digits\n",
    "    Y_train = Y_train_digits\n",
    "    Y_test = Y_test_digits\n",
    "  elif data == 'fashion':\n",
    "    X_train = X_train_fashion\n",
    "    X_test = X_test_fashion\n",
    "    Y_train = Y_train_fashion\n",
    "    Y_test = Y_test_fashion\n",
    "  else:\n",
    "    raise 'Unsupported dataset: %s' %data\n",
    "\n",
    "  # Train the model.\n",
    "  print('Training...')\n",
    "  history = model.fit(\n",
    "    x=X_train,\n",
    "    y=Y_train,\n",
    "    epochs=num_epochs,\n",
    "    batch_size=64,\n",
    "    validation_split=0.1,\n",
    "    verbose=0)\n",
    "\n",
    "  # Retrieve the training metrics (after each train epoch) and the final test\n",
    "  # accuracy.\n",
    "  train_accuracy = history.history['accuracy']\n",
    "  val_accuracy = history.history['val_accuracy']\n",
    "  plt.plot(train_accuracy, label='train_accuracy')\n",
    "  plt.plot(val_accuracy, label='validation accuracy')\n",
    "  plt.xticks(range(num_epochs))\n",
    "  plt.xlabel('Train epochs')\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "\n",
    "  test_accuracy = model.evaluate(x=X_test, y=Y_test, verbose=0,\n",
    "                                 return_dict=True)['accuracy']\n",
    "  return test_accuracy\n",
    "\n",
    "print('Test Accuracy: %1.4f' %train_and_evaluate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0Ewe-W8IT-J"
   },
   "source": [
    "---\n",
    "### Exercise 2 (8 points)\n",
    "\n",
    "Run experiments and fill in the test results in the table below. Feel free to extend the table to more experiments as you see fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_ddqOToQ6WW"
   },
   "source": [
    "#### Student Solution\n",
    "\n",
    "DATA | HIDDEN SIZES | ACTIVATION | OPTIMIZER | LEARNING RATE | #PARAMETERS | TEST ACCURACY\n",
    "-|-|-|-|-|-|-\n",
    "digits|[]|tanh|SGD|0.01||\n",
    "digits|[]|relu|SGD|0.01||\n",
    "digits|[]|relu|Adam|0.01||\n",
    "digits|[128]|relu|Adam|0.01||\n",
    "digits|[256,128]|relu|Adam|0.01||\n",
    "-\n",
    "fashion|[]|tanh|SGD|0.01||\n",
    "fashion|[]|relu|SGD|0.01||\n",
    "fashion|[]|relu|Adam|0.01||\n",
    "fashion|[128]|relu|Adam|0.01||\n",
    "fashion|[256,128]|relu|Adam|0.01||\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMlQhpKHdte3dv5Jw16gtIs",
   "collapsed_sections": [],
   "name": "06 Neural Networks.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
